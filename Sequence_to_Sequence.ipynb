{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence to Sequence.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+8LGt06HE8Dte2J6gWXV0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junanda/machine-learning/blob/main/Sequence_to_Sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KJBncaAvvrH"
      },
      "source": [
        "# **Sequence to Sequence for performing number addition**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbWuwOH6KeUc"
      },
      "source": [
        "### **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orl6WRh_vuyn"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# parameter model and dataset\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAX_LENGTH = DIGITS + 1 + DIGITS"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RifRKZvKwno"
      },
      "source": [
        "## **Prepare data before training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cemFHCkEw1W9"
      },
      "source": [
        "class CharacterTable:\n",
        "    \"\"\"\n",
        "    Given a set of character:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output \n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        self.charts = sorted(set(chars))\n",
        "        self.chart_indices = dict((c, i) for i, c in enumerate(self.charts))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.charts))\n",
        "    \n",
        "    def encode(self, C, num_rows):\n",
        "        x = np.zeros((num_rows, len(self.charts)))\n",
        "\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.chart_indices[c]] = 1\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        \n",
        "        return \"\".join(self.indices_char[x] for x in x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa6uAnZwLD88"
      },
      "source": [
        "## **Generating Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCBYxLoe2HOm",
        "outputId": "14578171-7ecb-4323-d524-519c2ed2f7f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# all the numbers, plus sign and space for padding\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "question = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data\")\n",
        "\n",
        "while len(question) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "    # skipp any addition question we've already seen\n",
        "    # also skip any such that x+Y == Y+x (hence to sorting)\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # pad the data with spaces suxh that if is always MAXLEN\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAX_LENGTH - len(q))\n",
        "    ans = str(a+b)\n",
        "\n",
        "    # answer can be of maximum size digits + 1\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    \n",
        "    question.append(query)\n",
        "    expected.append(ans)\n",
        "\n",
        "print(\"Total Questions: \", len(question))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data\n",
            "Total Questions:  50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQjR6dSd7C3L",
        "outputId": "215a907a-ec5c-46dd-c44d-9b18fe90651b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question[:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['   4+94',\n",
              " '  138+6',\n",
              " '  1+055',\n",
              " ' 24+492',\n",
              " '  606+4',\n",
              " '   53+8',\n",
              " '  428+9',\n",
              " '318+288',\n",
              " '  497+0',\n",
              " '  165+5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GFIpXUS7LNT",
        "outputId": "601d98db-d8f0-4df2-9ee7-46c771b709f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Vectorize\")\n",
        "x = np.zeros((len(question), MAX_LENGTH, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(question), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(question):\n",
        "    x[i] = ctable.encode(sentence, MAX_LENGTH)\n",
        "\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# shuffle (x,y) in unison as the later parts of x will almost all be larger digits\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicit set apart 10% for validation data that we never train over\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorize\n",
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SMIutoIT2WO"
      },
      "source": [
        "## **Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARxOPJ8IRLth",
        "outputId": "b8b28935-d79b-4a83-fb2b-c7434d36ee97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"build Model\")\n",
        "num_layers = 1\n",
        "\n",
        "model = keras.Sequential()\n",
        "# Encode the input sequence using LSTM, producing an output of size 128\n",
        "# Note: In a Situation where your input sequences have a variable length,\n",
        "# use input_shape = (None, num_feature)\n",
        "model.add(layers.LSTM(128, input_shape=(MAX_LENGTH, len(chars))))\n",
        "# as decoder RNN's input, repeatedly provide with the last output of RNN for each time step.\n",
        "# Repeat 'DIGITS + 1' times as that's the naximum length of output, e.g., when DIGITS = 3, max output is 999+999=1998\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# the Decoder RNN could be multiple layers stacked or single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build Model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ja7Fqs7A9wo"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrjnVa6EA0Uv",
        "outputId": "e343bb87-3113-4550-b3f3-b9a911cd85b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 30\n",
        "batch_size=32\n",
        "\n",
        "# dataset\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration, \", epoch)\n",
        "    model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_val, y_val),)\n",
        "    # select 10 samples from the validation set at random so we can visualize errors\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        quess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "\n",
        "        if correct == quess:\n",
        "            print(\"Benar \" + quess)\n",
        "        else:\n",
        "            print(\"Salah \"+ quess)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration,  1\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
            "Q 57+533  T 590  Benar 590 \n",
            "Q 934+84  T 1018 Benar 1018\n",
            "Q 871+3   T 874  Benar 874 \n",
            "Q 10+725  T 735  Benar 735 \n",
            "Q 643+551 T 1194 Benar 1194\n",
            "Q 39+125  T 164  Benar 164 \n",
            "Q 12+592  T 604  Benar 604 \n",
            "Q 60+90   T 150  Benar 150 \n",
            "Q 580+3   T 583  Benar 583 \n",
            "Q 385+61  T 446  Benar 446 \n",
            "\n",
            "Iteration,  2\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0139 - val_accuracy: 0.9962\n",
            "Q 83+5    T 88   Benar 88  \n",
            "Q 929+488 T 1417 Benar 1417\n",
            "Q 257+11  T 268  Benar 268 \n",
            "Q 73+235  T 308  Benar 308 \n",
            "Q 688+38  T 726  Benar 726 \n",
            "Q 446+42  T 488  Benar 488 \n",
            "Q 285+168 T 453  Benar 453 \n",
            "Q 182+3   T 185  Benar 185 \n",
            "Q 5+413   T 418  Benar 418 \n",
            "Q 34+850  T 884  Benar 884 \n",
            "\n",
            "Iteration,  3\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0248 - val_accuracy: 0.9920\n",
            "Q 58+31   T 89   Benar 89  \n",
            "Q 846+376 T 1222 Benar 1222\n",
            "Q 607+5   T 612  Benar 612 \n",
            "Q 648+46  T 694  Benar 694 \n",
            "Q 199+400 T 599  Benar 599 \n",
            "Q 338+9   T 347  Benar 347 \n",
            "Q 93+491  T 584  Benar 584 \n",
            "Q 60+301  T 361  Benar 361 \n",
            "Q 8+953   T 961  Benar 961 \n",
            "Q 38+589  T 627  Benar 627 \n",
            "\n",
            "Iteration,  4\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "Q 147+78  T 225  Benar 225 \n",
            "Q 831+770 T 1601 Benar 1601\n",
            "Q 623+797 T 1420 Benar 1420\n",
            "Q 110+722 T 832  Benar 832 \n",
            "Q 47+877  T 924  Benar 924 \n",
            "Q 55+275  T 330  Benar 330 \n",
            "Q 379+89  T 468  Benar 468 \n",
            "Q 31+401  T 432  Benar 432 \n",
            "Q 30+568  T 598  Benar 598 \n",
            "Q 9+636   T 645  Benar 645 \n",
            "\n",
            "Iteration,  5\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.0339 - val_accuracy: 0.9929\n",
            "Q 25+508  T 533  Benar 533 \n",
            "Q 410+94  T 504  Benar 504 \n",
            "Q 79+15   T 94   Benar 94  \n",
            "Q 23+100  T 123  Benar 123 \n",
            "Q 350+108 T 458  Benar 458 \n",
            "Q 285+948 T 1233 Benar 1233\n",
            "Q 958+85  T 1043 Benar 1043\n",
            "Q 439+764 T 1203 Benar 1203\n",
            "Q 285+37  T 322  Benar 322 \n",
            "Q 78+219  T 297  Benar 297 \n",
            "\n",
            "Iteration,  6\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Q 226+1   T 227  Benar 227 \n",
            "Q 223+206 T 429  Benar 429 \n",
            "Q 264+845 T 1109 Benar 1109\n",
            "Q 838+83  T 921  Benar 921 \n",
            "Q 48+883  T 931  Benar 931 \n",
            "Q 764+524 T 1288 Benar 1288\n",
            "Q 386+644 T 1030 Benar 1030\n",
            "Q 574+368 T 942  Benar 942 \n",
            "Q 651+1   T 652  Benar 652 \n",
            "Q 86+541  T 627  Benar 627 \n",
            "\n",
            "Iteration,  7\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
            "Q 363+563 T 926  Benar 926 \n",
            "Q 519+82  T 601  Benar 601 \n",
            "Q 967+247 T 1214 Benar 1214\n",
            "Q 92+753  T 845  Benar 845 \n",
            "Q 6+245   T 251  Benar 251 \n",
            "Q 8+631   T 639  Benar 639 \n",
            "Q 246+45  T 291  Benar 291 \n",
            "Q 791+933 T 1724 Benar 1724\n",
            "Q 16+58   T 74   Benar 74  \n",
            "Q 774+749 T 1523 Benar 1523\n",
            "\n",
            "Iteration,  8\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
            "Q 89+63   T 152  Benar 152 \n",
            "Q 676+41  T 717  Benar 717 \n",
            "Q 585+57  T 642  Benar 642 \n",
            "Q 90+464  T 554  Benar 554 \n",
            "Q 104+36  T 140  Benar 140 \n",
            "Q 609+876 T 1485 Benar 1485\n",
            "Q 870+17  T 887  Benar 887 \n",
            "Q 1+316   T 317  Benar 317 \n",
            "Q 779+761 T 1540 Benar 1540\n",
            "Q 1+886   T 887  Benar 887 \n",
            "\n",
            "Iteration,  9\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
            "Q 915+8   T 923  Benar 923 \n",
            "Q 991+92  T 1083 Benar 1083\n",
            "Q 323+728 T 1051 Benar 1051\n",
            "Q 447+891 T 1338 Benar 1338\n",
            "Q 59+380  T 439  Benar 439 \n",
            "Q 298+674 T 972  Benar 972 \n",
            "Q 20+27   T 47   Benar 47  \n",
            "Q 765+41  T 806  Benar 806 \n",
            "Q 861+768 T 1629 Benar 1629\n",
            "Q 32+493  T 525  Benar 525 \n",
            "\n",
            "Iteration,  10\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
            "Q 408+528 T 936  Benar 936 \n",
            "Q 577+632 T 1209 Benar 1209\n",
            "Q 30+7    T 37   Benar 37  \n",
            "Q 526+5   T 531  Benar 531 \n",
            "Q 824+592 T 1416 Benar 1416\n",
            "Q 434+438 T 872  Benar 872 \n",
            "Q 17+129  T 146  Benar 146 \n",
            "Q 512+47  T 559  Benar 559 \n",
            "Q 91+52   T 143  Benar 143 \n",
            "Q 885+91  T 976  Benar 976 \n",
            "\n",
            "Iteration,  11\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
            "Q 388+2   T 390  Benar 390 \n",
            "Q 897+815 T 1712 Benar 1712\n",
            "Q 268+16  T 284  Benar 284 \n",
            "Q 813+169 T 982  Benar 982 \n",
            "Q 56+968  T 1024 Benar 1024\n",
            "Q 436+38  T 474  Benar 474 \n",
            "Q 464+755 T 1219 Benar 1219\n",
            "Q 760+802 T 1562 Benar 1562\n",
            "Q 988+3   T 991  Benar 991 \n",
            "Q 1+713   T 714  Benar 714 \n",
            "\n",
            "Iteration,  12\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Q 954+75  T 1029 Benar 1029\n",
            "Q 64+97   T 161  Benar 161 \n",
            "Q 63+558  T 621  Benar 621 \n",
            "Q 520+599 T 1119 Benar 1119\n",
            "Q 11+739  T 750  Benar 750 \n",
            "Q 702+62  T 764  Benar 764 \n",
            "Q 621+254 T 875  Benar 875 \n",
            "Q 71+356  T 427  Benar 427 \n",
            "Q 66+353  T 419  Benar 419 \n",
            "Q 57+2    T 59   Benar 59  \n",
            "\n",
            "Iteration,  13\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Q 48+30   T 78   Benar 78  \n",
            "Q 30+618  T 648  Benar 648 \n",
            "Q 565+9   T 574  Benar 574 \n",
            "Q 390+636 T 1026 Benar 1026\n",
            "Q 236+342 T 578  Benar 578 \n",
            "Q 897+292 T 1189 Benar 1189\n",
            "Q 80+134  T 214  Benar 214 \n",
            "Q 761+2   T 763  Benar 763 \n",
            "Q 83+323  T 406  Benar 406 \n",
            "Q 61+663  T 724  Benar 724 \n",
            "\n",
            "Iteration,  14\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
            "Q 85+900  T 985  Benar 985 \n",
            "Q 35+150  T 185  Benar 185 \n",
            "Q 40+305  T 345  Benar 345 \n",
            "Q 511+78  T 589  Benar 589 \n",
            "Q 441+47  T 488  Benar 488 \n",
            "Q 0+568   T 568  Benar 568 \n",
            "Q 541+2   T 543  Benar 543 \n",
            "Q 8+173   T 181  Benar 181 \n",
            "Q 21+768  T 789  Benar 789 \n",
            "Q 118+178 T 296  Benar 296 \n",
            "\n",
            "Iteration,  15\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
            "Q 60+603  T 663  Benar 663 \n",
            "Q 82+109  T 191  Benar 191 \n",
            "Q 408+528 T 936  Benar 936 \n",
            "Q 295+885 T 1180 Benar 1180\n",
            "Q 342+72  T 414  Benar 414 \n",
            "Q 76+529  T 605  Benar 605 \n",
            "Q 717+426 T 1143 Benar 1143\n",
            "Q 732+690 T 1422 Benar 1422\n",
            "Q 46+676  T 722  Benar 722 \n",
            "Q 254+88  T 342  Benar 342 \n",
            "\n",
            "Iteration,  16\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0334 - val_accuracy: 0.9907\n",
            "Q 11+831  T 842  Benar 842 \n",
            "Q 983+42  T 1025 Benar 1025\n",
            "Q 175+9   T 184  Benar 184 \n",
            "Q 670+183 T 853  Benar 853 \n",
            "Q 795+16  T 811  Benar 811 \n",
            "Q 131+53  T 184  Benar 184 \n",
            "Q 947+16  T 963  Benar 963 \n",
            "Q 751+49  T 800  Benar 800 \n",
            "Q 634+997 T 1631 Benar 1631\n",
            "Q 700+728 T 1428 Benar 1428\n",
            "\n",
            "Iteration,  17\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
            "Q 148+1   T 149  Benar 149 \n",
            "Q 23+35   T 58   Benar 58  \n",
            "Q 31+401  T 432  Benar 432 \n",
            "Q 55+452  T 507  Benar 507 \n",
            "Q 524+1   T 525  Benar 525 \n",
            "Q 408+856 T 1264 Benar 1264\n",
            "Q 348+14  T 362  Benar 362 \n",
            "Q 991+92  T 1083 Benar 1083\n",
            "Q 32+908  T 940  Benar 940 \n",
            "Q 368+1   T 369  Benar 369 \n",
            "\n",
            "Iteration,  18\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0706 - val_accuracy: 0.9779\n",
            "Q 464+89  T 553  Benar 553 \n",
            "Q 40+841  T 881  Benar 881 \n",
            "Q 225+35  T 260  Benar 260 \n",
            "Q 968+342 T 1310 Benar 1310\n",
            "Q 457+81  T 538  Benar 538 \n",
            "Q 347+60  T 407  Benar 407 \n",
            "Q 9+286   T 295  Benar 295 \n",
            "Q 914+9   T 923  Benar 923 \n",
            "Q 700+195 T 895  Benar 895 \n",
            "Q 288+2   T 290  Benar 290 \n",
            "\n",
            "Iteration,  19\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Q 291+2   T 293  Benar 293 \n",
            "Q 912+522 T 1434 Benar 1434\n",
            "Q 905+437 T 1342 Benar 1342\n",
            "Q 291+624 T 915  Benar 915 \n",
            "Q 6+140   T 146  Benar 146 \n",
            "Q 310+4   T 314  Benar 314 \n",
            "Q 927+86  T 1013 Benar 1013\n",
            "Q 211+0   T 211  Benar 211 \n",
            "Q 1+353   T 354  Benar 354 \n",
            "Q 223+96  T 319  Benar 319 \n",
            "\n",
            "Iteration,  20\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0790 - val_accuracy: 0.9738\n",
            "Q 415+29  T 444  Salah 434 \n",
            "Q 492+72  T 564  Benar 564 \n",
            "Q 14+629  T 643  Benar 643 \n",
            "Q 781+2   T 783  Salah 792 \n",
            "Q 2+468   T 470  Benar 470 \n",
            "Q 553+17  T 570  Benar 570 \n",
            "Q 784+99  T 883  Salah 884 \n",
            "Q 701+8   T 709  Benar 709 \n",
            "Q 9+202   T 211  Benar 211 \n",
            "Q 78+647  T 725  Benar 725 \n",
            "\n",
            "Iteration,  21\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Q 16+592  T 608  Benar 608 \n",
            "Q 76+25   T 101  Benar 101 \n",
            "Q 77+568  T 645  Benar 645 \n",
            "Q 3+458   T 461  Benar 461 \n",
            "Q 976+9   T 985  Benar 985 \n",
            "Q 63+701  T 764  Benar 764 \n",
            "Q 20+27   T 47   Benar 47  \n",
            "Q 153+853 T 1006 Benar 1006\n",
            "Q 194+995 T 1189 Benar 1189\n",
            "Q 1+455   T 456  Benar 456 \n",
            "\n",
            "Iteration,  22\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0113 - val_accuracy: 0.9966\n",
            "Q 223+96  T 319  Benar 319 \n",
            "Q 752+98  T 850  Benar 850 \n",
            "Q 2+381   T 383  Benar 383 \n",
            "Q 555+22  T 577  Benar 577 \n",
            "Q 870+50  T 920  Benar 920 \n",
            "Q 274+87  T 361  Benar 361 \n",
            "Q 6+244   T 250  Benar 250 \n",
            "Q 399+89  T 488  Benar 488 \n",
            "Q 603+800 T 1403 Benar 1403\n",
            "Q 654+972 T 1626 Benar 1626\n",
            "\n",
            "Iteration,  23\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
            "Q 176+904 T 1080 Benar 1080\n",
            "Q 14+593  T 607  Benar 607 \n",
            "Q 972+8   T 980  Benar 980 \n",
            "Q 215+861 T 1076 Benar 1076\n",
            "Q 13+617  T 630  Benar 630 \n",
            "Q 644+38  T 682  Benar 682 \n",
            "Q 929+488 T 1417 Benar 1417\n",
            "Q 8+350   T 358  Benar 358 \n",
            "Q 30+73   T 103  Benar 103 \n",
            "Q 15+338  T 353  Benar 353 \n",
            "\n",
            "Iteration,  24\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 8.6517e-04 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Q 2+240   T 242  Benar 242 \n",
            "Q 8+854   T 862  Benar 862 \n",
            "Q 11+407  T 418  Benar 418 \n",
            "Q 2+606   T 608  Benar 608 \n",
            "Q 581+97  T 678  Benar 678 \n",
            "Q 156+16  T 172  Benar 172 \n",
            "Q 55+884  T 939  Benar 939 \n",
            "Q 61+311  T 372  Benar 372 \n",
            "Q 0+794   T 794  Benar 794 \n",
            "Q 636+395 T 1031 Benar 1031\n",
            "\n",
            "Iteration,  25\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Q 814+6   T 820  Benar 820 \n",
            "Q 692+851 T 1543 Benar 1543\n",
            "Q 69+959  T 1028 Benar 1028\n",
            "Q 670+183 T 853  Benar 853 \n",
            "Q 91+196  T 287  Benar 287 \n",
            "Q 530+834 T 1364 Benar 1364\n",
            "Q 633+276 T 909  Benar 909 \n",
            "Q 24+94   T 118  Benar 118 \n",
            "Q 809+2   T 811  Benar 811 \n",
            "Q 693+1   T 694  Benar 694 \n",
            "\n",
            "Iteration,  26\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Q 705+2   T 707  Benar 707 \n",
            "Q 86+468  T 554  Benar 554 \n",
            "Q 76+637  T 713  Benar 713 \n",
            "Q 82+837  T 919  Benar 919 \n",
            "Q 99+136  T 235  Benar 235 \n",
            "Q 0+932   T 932  Benar 932 \n",
            "Q 60+152  T 212  Benar 212 \n",
            "Q 410+61  T 471  Benar 471 \n",
            "Q 222+39  T 261  Benar 261 \n",
            "Q 997+487 T 1484 Benar 1484\n",
            "\n",
            "Iteration,  27\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0426 - val_accuracy: 0.9874\n",
            "Q 323+728 T 1051 Benar 1051\n",
            "Q 86+245  T 331  Benar 331 \n",
            "Q 746+789 T 1535 Salah 1536\n",
            "Q 930+279 T 1209 Benar 1209\n",
            "Q 269+87  T 356  Benar 356 \n",
            "Q 19+306  T 325  Benar 325 \n",
            "Q 788+34  T 822  Benar 822 \n",
            "Q 720+9   T 729  Benar 729 \n",
            "Q 46+12   T 58   Benar 58  \n",
            "Q 157+49  T 206  Benar 206 \n",
            "\n",
            "Iteration,  28\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Q 654+70  T 724  Benar 724 \n",
            "Q 50+31   T 81   Benar 81  \n",
            "Q 64+162  T 226  Benar 226 \n",
            "Q 9+0     T 9    Benar 9   \n",
            "Q 977+90  T 1067 Benar 1067\n",
            "Q 485+0   T 485  Benar 485 \n",
            "Q 909+430 T 1339 Benar 1339\n",
            "Q 243+929 T 1172 Benar 1172\n",
            "Q 114+60  T 174  Benar 174 \n",
            "Q 9+791   T 800  Benar 800 \n",
            "\n",
            "Iteration,  29\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0300 - val_accuracy: 0.9905\n",
            "Q 560+228 T 788  Benar 788 \n",
            "Q 93+547  T 640  Benar 640 \n",
            "Q 493+462 T 955  Benar 955 \n",
            "Q 66+50   T 116  Benar 116 \n",
            "Q 888+33  T 921  Benar 921 \n",
            "Q 632+90  T 722  Benar 722 \n",
            "Q 7+889   T 896  Benar 896 \n",
            "Q 6+817   T 823  Benar 823 \n",
            "Q 603+800 T 1403 Benar 1403\n",
            "Q 539+614 T 1153 Salah 1163\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}